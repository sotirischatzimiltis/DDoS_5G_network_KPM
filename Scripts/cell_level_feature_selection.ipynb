{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637fe483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac429b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load Cell based dataset\"\"\"\n",
    "df_cell = pd.read_csv('../Datasets/enb_counters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465cbcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       timestamp instance_id  cell_X_dl_bitrate  \\\n",
      "0      2024-01-24 14:00:00+00:00    65a5700c            96029.0   \n",
      "1      2024-01-24 14:00:00+00:00    65b119a2                NaN   \n",
      "2      2024-01-24 14:00:05+00:00    65a5700c            95975.0   \n",
      "3      2024-01-24 14:00:05+00:00    65b119a2                NaN   \n",
      "4      2024-01-24 14:00:10+00:00    65a5700c            93107.0   \n",
      "...                          ...         ...                ...   \n",
      "58213  2024-01-25 16:59:50+00:00    65a5700c                NaN   \n",
      "58214  2024-01-25 16:59:50+00:00    65b119a8            13583.0   \n",
      "58215  2024-01-25 16:59:55+00:00    65b119a2            28921.0   \n",
      "58216  2024-01-25 16:59:55+00:00    65a5700c                NaN   \n",
      "58217  2024-01-25 16:59:55+00:00    65b119a8            12561.0   \n",
      "\n",
      "       cell_X_dl_err  cell_X_dl_gbr_use_avg  cell_X_dl_gbr_use_max  \\\n",
      "0                0.0                    0.0                    0.0   \n",
      "1                NaN                    NaN                    NaN   \n",
      "2                0.0                    0.0                    0.0   \n",
      "3                NaN                    NaN                    NaN   \n",
      "4                0.0                    0.0                    0.0   \n",
      "...              ...                    ...                    ...   \n",
      "58213            NaN                    NaN                    NaN   \n",
      "58214            NaN                    0.0                    0.0   \n",
      "58215            0.0                    0.0                    0.0   \n",
      "58216            NaN                    NaN                    NaN   \n",
      "58217            NaN                    0.0                    0.0   \n",
      "\n",
      "       cell_X_dl_gbr_use_min  cell_X_dl_retx  cell_X_dl_sched_users_avg  \\\n",
      "0                        0.0            42.0                      0.034   \n",
      "1                        NaN             NaN                        NaN   \n",
      "2                        0.0            52.0                      0.034   \n",
      "3                        NaN             NaN                        NaN   \n",
      "4                        0.0            40.0                      0.031   \n",
      "...                      ...             ...                        ...   \n",
      "58213                    NaN             NaN                        NaN   \n",
      "58214                    0.0             2.0                      0.014   \n",
      "58215                    0.0            26.0                      0.016   \n",
      "58216                    NaN             NaN                        NaN   \n",
      "58217                    0.0             5.0                      0.013   \n",
      "\n",
      "       cell_X_dl_sched_users_max  ...  rf_tx_cpu_time  rf_tx_sample_rate  \\\n",
      "0                            2.0  ...             5.0          61.440203   \n",
      "1                            NaN  ...             NaN                NaN   \n",
      "2                            2.0  ...             5.0          61.439763   \n",
      "3                            NaN  ...             NaN                NaN   \n",
      "4                            2.0  ...             5.0          61.440072   \n",
      "...                          ...  ...             ...                ...   \n",
      "58213                        NaN  ...             NaN                NaN   \n",
      "58214                        2.0  ...             1.8          46.080116   \n",
      "58215                        2.0  ...             4.9          61.439737   \n",
      "58216                        NaN  ...             NaN                NaN   \n",
      "58217                        2.0  ...             1.8          46.079982   \n",
      "\n",
      "       cell_id  cell_X_erab_count_avg  cell_X_erab_count_max  \\\n",
      "0          1.0                    NaN                    NaN   \n",
      "1          NaN                    NaN                    NaN   \n",
      "2          1.0                    NaN                    NaN   \n",
      "3          NaN                    NaN                    NaN   \n",
      "4          1.0                    NaN                    NaN   \n",
      "...        ...                    ...                    ...   \n",
      "58213      NaN                    NaN                    NaN   \n",
      "58214      2.0                    6.0                    6.0   \n",
      "58215      1.0                    NaN                    NaN   \n",
      "58216      NaN                    NaN                    NaN   \n",
      "58217      2.0                    6.0                    6.0   \n",
      "\n",
      "       cell_X_erab_count_min  msg_ng_error_indication  \\\n",
      "0                        NaN                      NaN   \n",
      "1                        NaN                      NaN   \n",
      "2                        NaN                      NaN   \n",
      "3                        NaN                      NaN   \n",
      "4                        NaN                      NaN   \n",
      "...                      ...                      ...   \n",
      "58213                    NaN                      NaN   \n",
      "58214                    6.0                      6.0   \n",
      "58215                    NaN                      NaN   \n",
      "58216                    NaN                      NaN   \n",
      "58217                    6.0                      6.0   \n",
      "\n",
      "       msg_ng_initial_context_setup_failure  \\\n",
      "0                                       NaN   \n",
      "1                                       NaN   \n",
      "2                                       NaN   \n",
      "3                                       NaN   \n",
      "4                                       NaN   \n",
      "...                                     ...   \n",
      "58213                                   NaN   \n",
      "58214                                   1.0   \n",
      "58215                                   NaN   \n",
      "58216                                   NaN   \n",
      "58217                                   1.0   \n",
      "\n",
      "       msg_xn_ng_ran_node_configuration_update_acknowledge_recv  \\\n",
      "0                                                    NaN          \n",
      "1                                                    NaN          \n",
      "2                                                    NaN          \n",
      "3                                                    NaN          \n",
      "4                                                    NaN          \n",
      "...                                                  ...          \n",
      "58213                                                NaN          \n",
      "58214                                                2.0          \n",
      "58215                                                NaN          \n",
      "58216                                                NaN          \n",
      "58217                                                2.0          \n",
      "\n",
      "       msg_xn_ng_ran_node_configuration_update_sent  \n",
      "0                                               NaN  \n",
      "1                                               NaN  \n",
      "2                                               NaN  \n",
      "3                                               NaN  \n",
      "4                                               NaN  \n",
      "...                                             ...  \n",
      "58213                                           NaN  \n",
      "58214                                           2.0  \n",
      "58215                                           NaN  \n",
      "58216                                           NaN  \n",
      "58217                                           2.0  \n",
      "\n",
      "[58218 rows x 107 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf6b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with singular values\n",
    "singular_columns = df_cell.columns[df_cell.nunique() == 1]\n",
    "df_cell = df_cell.drop(columns=singular_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931666d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26730c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove instance id since we have cell_id to combine datasets\n",
    "drop_col = 'instance_id'\n",
    "df_cell = df_cell.drop(columns=drop_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp feature from object to datetime\n",
    "df_cell['timestamp'] = pd.to_datetime(df_cell['timestamp'])\n",
    "df_cell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4493c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where only the first feature has value\n",
    "print(\"Number of instances before: \",len(df_cell))\n",
    "df_cell = df_cell[df_cell.iloc[:, 1:].notna().any(axis=1)].reset_index(drop=True)\n",
    "print(\"Number of instances after: \",len(df_cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab112b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis of cell features for removal\n",
    "columns = df_cell.columns\n",
    "\n",
    "# Print how many Nan values exist in each column\n",
    "nan_counts = df_cell.isnull().sum()\n",
    "for column, count in nan_counts.items():\n",
    "    print(f\"Column '{column}': {count} NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b8ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to remove due to NaN values:\n",
    "features_to_drop = ['cell_X_dl_err','cell_X_dl_use_avg','cell_X_dl_use_max','cell_X_drb_count_avg',\n",
    "                    'cell_X_drb_count_max','cell_X_drb_count_min','cell_X_ul_err','cell_X_ul_use_avg',\n",
    "                    'cell_X_ul_use_max','msg_ng_paging','msg_ng_path_switch_request',\n",
    "                    'msg_ng_path_switch_request_acknowledge','msg_ng_pdu_session_resource_notify',\n",
    "                    'msg_xn_handover_request_acknowledge_recv','msg_xn_handover_request_acknowledge_sent',\n",
    "                    'msg_xn_handover_request_recv','msg_xn_handover_request_sent',\n",
    "                    'msg_xn_ng_ran_node_configuration_update_acknowledge_sent', 'msg_xn_ng_ran_node_configuration_update_recv',\n",
    "                    'msg_xn_sn_status_transfer_recv','msg_xn_sn_status_transfer_sent','msg_xn_ue_context_release_recv',\n",
    "                    'msg_xn_ue_context_release_sent','rf_samples_tx2_count','rf_samples_tx2_max','rf_samples_tx2_rms',\n",
    "                    'cell_X_erab_count_avg','cell_X_erab_count_max','cell_X_erab_count_min','msg_ng_error_indication']\n",
    "\n",
    "# remove columns\n",
    "df_cell = df_cell.drop(columns=features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1940e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the instances into clusters using:\n",
    "# variance thresholding\n",
    "# correlation-based feature selection\n",
    "# and feature selection using clustering\n",
    "\n",
    "# remove timestamp and cellid \n",
    "data = df_cell.drop(columns = ['timestamp', 'cell_id'])\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance thresholding \n",
    "\n",
    "# Set threshold to a value. Features with variance lower than this will be removed.\n",
    "threshold = 0.9 # up to 0.9 no features were removed. \n",
    "selector = VarianceThreshold(threshold)\n",
    "\n",
    "# Fit the selector to the scaled data\n",
    "selector.fit(df_scaled)\n",
    "\n",
    "# Transform the data to keep only the features with variance above the threshold\n",
    "df_reduced = selector.transform(df_scaled)\n",
    "\n",
    "# Convert the result back to a DataFrame with original feature names\n",
    "df_reduced = pd.DataFrame(df_reduced, columns=[column for column, var in zip(data.columns, selector.variances_) if var > threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37863275",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Correlation based feature selection '''\n",
    "\n",
    "# make numpy array back to dataframe\n",
    "# df_scaled = pd.DataFrame(df_scaled, columns=[column for column in data.columns])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = data.corr().abs()\n",
    "\n",
    "# Set the correlation threshold\n",
    "threshold = 0.8\n",
    "\n",
    "# Identify pairs of features with correlation greater than the threshold\n",
    "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find columns to drop\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "# Display the columns to drop\n",
    "print(\"Columns to Drop:\")\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1edd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced_corr = data.drop(columns = to_drop)\n",
    "df_reduced_corr.head()\n",
    "features_correlation = list(df_reduced_corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfcf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Feature selection using clustering'''\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(df_scaled)\n",
    "\n",
    "# Calculate the silhouette score to evaluate clustering performance\n",
    "silhouette_avg = silhouette_score(df_scaled, kmeans.labels_)\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "# Determine feature importance\n",
    "# One way to determine feature importance is to analyze the cluster centers\n",
    "feature_importance = np.abs(kmeans.cluster_centers_).mean(axis=0)\n",
    "feature_importance_df = pd.DataFrame({'Feature': data.columns, 'Importance': feature_importance})\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Select features with importance above a certain threshold\n",
    "threshold = 0.5 # * feature_importance.max()\n",
    "important_features = feature_importance_df[feature_importance_df['Importance'] >= threshold]['Feature']\n",
    "\n",
    "# Reduce the DataFrame to important features\n",
    "df_reduced_clustering = data[important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1dd014",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_reduced_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise clusters and the instances of each cluster \n",
    "clusters = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "df = data.copy()\n",
    "df['Cluster'] = clusters\n",
    "\n",
    "# Scatter plot of the clusters\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(x='cell_X_dl_retx', y='cell_X_ul_bitrate', hue='Cluster', data=df, palette='viridis', s=100)\n",
    "plt.title('Scatter Plot of Clusters')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec3082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of the number of instances in each cluster\n",
    "cluster_counts = df['Cluster'].value_counts().sort_index()\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=cluster_counts.index, y=cluster_counts.values, palette='viridis')\n",
    "plt.title('Number of Instances in Each Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between the remaining features to discard even more\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_reduced_clustering.corr().abs()\n",
    "\n",
    "# Set the correlation threshold\n",
    "threshold = 0.8\n",
    "\n",
    "# Identify pairs of features with correlation greater than the threshold\n",
    "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find columns to drop\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "# Display the columns to drop\n",
    "print(\"Columns to Drop:\")\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ac621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering and correlation features \n",
    "df_clustering_correlation = df_reduced_clustering.drop(columns = to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e52a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering_correlation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ed075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to save based on clustering and correlation\n",
    "final_columns = list(df_clustering_correlation.columns)\n",
    "print(final_columns)\n",
    "final_columns.extend(['timestamp','cell_id'])\n",
    "print(final_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_clustering_correlation = df_cell[final_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fdf905",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_clustering_correlation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_clustering_correlation.to_csv('cell_data_clustering_correlation.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_correlation.extend(['timestamp','cell_id'])\n",
    "final_df__correlation = df_cell[features_correlation]\n",
    "final_df__correlation.to_csv('cell_data_correlation.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78579b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
